{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 袁倫祥醫師 GPT-SoVITS 語音克隆訓練\n",
    "\n",
    "## 使用前準備\n",
    "1. **Runtime > Change runtime type > GPU (T4)**\n",
    "2. 依序執行每個 cell\n",
    "3. 訓練完成後下載模型到本地 Mac\n",
    "\n",
    "**預估時間**: 安裝 ~5 min, 模型下載 ~10 min, 預處理 ~15 min, SoVITS 訓練 ~30 min, GPT 訓練 ~60 min"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Step 1: 檢查 GPU 並安裝 GPT-SoVITS\nimport os\nos.system(\"nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\")\n\n# Clone (跳過如果已存在)\nif not os.path.exists(\"/content/GPT-SoVITS/.git\"):\n    os.system(\"git clone --depth 1 https://github.com/RVC-Boss/GPT-SoVITS.git /content/GPT-SoVITS\")\nos.chdir(\"/content/GPT-SoVITS\")\n\n# 安裝依賴 - 不用 tail 過濾，顯示完整錯誤\nprint(\"安裝 requirements.txt...\")\nos.system(\"pip install -r requirements.txt\")\n\n# 明確補安裝容易失敗的套件 (requirements.txt 中 41 個套件有些會因衝突而跳過)\nprint(\"\\n補安裝關鍵套件...\")\nos.system(\"pip install onnxruntime jieba_fast cn2an pypinyin g2p_en jieba wordsegment \"\n          \"x-transformers rotary-embedding-torch sentencepiece split-lang fast-langdetect \"\n          \"ffmpeg-python PyYAML peft\")\nos.system(\"apt-get install -y -qq ffmpeg\")\n\n# 驗證 chinese2.py import chain (文字處理核心依賴)\nprint(\"\\n驗證 import chain:\")\nimport sys\nsys.path.insert(0, '/content/GPT-SoVITS/GPT_SoVITS')\ntry:\n    # 測試完整的 chinese text processing import chain\n    import importlib\n    for mod_name in ['cn2an', 'pypinyin', 'jieba_fast', 'onnxruntime', 'g2p_en',\n                     'wordsegment', 'x_transformers', 'sentencepiece']:\n        importlib.import_module(mod_name)\n        print(f\"  OK: {mod_name}\")\n    print(\"\\n\\u2705 安裝完成！\")\nexcept ImportError as e:\n    print(f\"\\n\\u26a0\\ufe0f 缺少套件: {e}\")\n    print(\"嘗試修復...\")\n    missing = str(e).split(\"'\")[1] if \"'\" in str(e) else str(e)\n    os.system(f\"pip install {missing}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Step 2: 下載訓練資料 (從 GitHub Release)\n",
    "import os, glob\n",
    "\n",
    "print(\"從 GitHub Release 下載訓練資料...\")\n",
    "os.system(\"wget -q https://github.com/lunhsiangyuan/yuan-voice-clone/releases/download/training-data-v1/yuan_training_data.zip -O /content/GPT-SoVITS/yuan_training_data.zip\")\n",
    "\n",
    "os.system(\"mkdir -p /content/GPT-SoVITS/training_data\")\n",
    "os.system(\"unzip -o /content/GPT-SoVITS/yuan_training_data.zip -d /content/GPT-SoVITS/training_data/\")\n",
    "\n",
    "wav_count = len(glob.glob(\"/content/GPT-SoVITS/training_data/audio/*.wav\"))\n",
    "list_files = glob.glob(\"/content/GPT-SoVITS/training_data/*.list\")\n",
    "print(f\"音檔數量: {wav_count}\")\n",
    "print(f\"標註檔案: {list_files}\")\n",
    "print(\"\\n\\u2705 訓練資料已就緒！\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Step 3: 下載預訓練模型 (~3.4GB)\nimport os\nos.chdir(\"/content/GPT-SoVITS\")\n\nos.system(\"pip install -q huggingface_hub\")\nprint(\"下載 GPT-SoVITS 預訓練模型...\")\nret = os.system(\"huggingface-cli download lj1995/GPT-SoVITS --local-dir GPT_SoVITS/pretrained_models --exclude '*.md' '.gitattributes' 'LICENSE*'\")\nif ret != 0:\n    print(\"重試中...\")\n    os.system(\"huggingface-cli download lj1995/GPT-SoVITS --local-dir GPT_SoVITS/pretrained_models --exclude '*.md' '.gitattributes' 'LICENSE*'\")\n\n# 補下載 HuBERT 權重 (lj1995 repo 不含實際權重)\nhubert_dir = \"GPT_SoVITS/pretrained_models/chinese-hubert-base\"\nos.makedirs(hubert_dir, exist_ok=True)\nif not (os.path.exists(f\"{hubert_dir}/pytorch_model.bin\") or os.path.exists(f\"{hubert_dir}/model.safetensors\")):\n    print(\"\\nHuBERT 權重缺失，直接下載...\")\n    os.system(f\"wget -q https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/pytorch_model.bin -O {hubert_dir}/pytorch_model.bin\")\n    os.system(f\"wget -q https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/config.json -O {hubert_dir}/config.json\")\n    os.system(f\"wget -q https://huggingface.co/TencentGameMate/chinese-hubert-base/resolve/main/preprocessor_config.json -O {hubert_dir}/preprocessor_config.json\")\n\n# 補下載 BERT 權重\nbert_dir = \"GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\"\nos.makedirs(bert_dir, exist_ok=True)\nif not (os.path.exists(f\"{bert_dir}/pytorch_model.bin\") or os.path.exists(f\"{bert_dir}/model.safetensors\")):\n    print(\"\\nBERT 權重缺失，直接下載...\")\n    os.system(f\"wget -q https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/pytorch_model.bin -O {bert_dir}/pytorch_model.bin\")\n    os.system(f\"wget -q https://huggingface.co/hfl/chinese-roberta-wwm-ext-large/resolve/main/config.json -O {bert_dir}/config.json\")\n\n# 驗證\nprint(\"\\n模型驗證:\")\nchecks = {\n    'gsv-v2final-pretrained': 'GPT_SoVITS/pretrained_models/gsv-v2final-pretrained',\n    'HuBERT weights': f'{hubert_dir}/pytorch_model.bin',\n    'BERT weights': f'{bert_dir}/pytorch_model.bin',\n}\nall_ok = True\nfor name, path in checks.items():\n    if os.path.exists(path):\n        if os.path.isfile(path):\n            size_mb = os.path.getsize(path) / 1024 / 1024\n            print(f\"  \\u2713 {name} ({size_mb:.0f} MB)\")\n        else:\n            print(f\"  \\u2713 {name} (dir)\")\n    else:\n        safetensors = path.replace('pytorch_model.bin', 'model.safetensors')\n        if os.path.exists(safetensors):\n            size_mb = os.path.getsize(safetensors) / 1024 / 1024\n            print(f\"  \\u2713 {name} ({size_mb:.0f} MB, safetensors)\")\n        else:\n            print(f\"  \\u2717 MISSING: {name}\")\n            all_ok = False\n\nif all_ok:\n    print(\"\\n\\u2705 預訓練模型全部就緒！\")\nelse:\n    print(\"\\n\\u26a0\\ufe0f 部分模型缺失，請檢查網路連線\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Step 4: 預處理 (文字處理 + HuBERT + 語義特徵提取)\nimport os, glob, subprocess, sys, shutil\nos.chdir(\"/content/GPT-SoVITS\")\n\nEXP_NAME = \"yuan\"\nWAV_DIR = \"/content/GPT-SoVITS/training_data\"\nOPT_DIR = f\"/content/GPT-SoVITS/output/training/{EXP_NAME}\"\nif os.path.isdir(OPT_DIR):\n    shutil.rmtree(OPT_DIR)\nos.makedirs(OPT_DIR, exist_ok=True)\n\n# === 標註檔轉絕對路徑 ===\norig_list = \"/content/GPT-SoVITS/training_data/transcript_corrected.list\"\nif not os.path.exists(orig_list):\n    lists = glob.glob(\"/content/GPT-SoVITS/training_data/*.list\")\n    orig_list = lists[0] if lists else None\n    if not orig_list: raise FileNotFoundError(\"找不到標註檔!\")\n\nLIST_FILE = f\"{OPT_DIR}/transcript_abs.list\"\nconverted = 0\nwith open(orig_list, 'r') as fin, open(LIST_FILE, 'w') as fout:\n    for line in fin:\n        line = line.strip()\n        if not line: continue\n        parts = line.split('|')\n        if len(parts) >= 4:\n            wav_abs = os.path.join(WAV_DIR, parts[0])\n            if os.path.exists(wav_abs):\n                parts[0] = wav_abs\n                fout.write('|'.join(parts) + '\\n')\n                converted += 1\nprint(f\"標註檔: {converted} 筆\")\n\n# === 預訓練模型 ===\npretrained_base = \"GPT_SoVITS/pretrained_models\"\nS2G_PATH = next((p for p in [\n    f\"{pretrained_base}/gsv-v2final-pretrained/s2G2333k.pth\",\n    f\"{pretrained_base}/s2G488k.pth\",\n] if os.path.exists(p)), None)\n\n# === 環境變數 (inp_wav_dir='' 讓腳本用絕對路徑) ===\nenv = os.environ.copy()\nenv.update({\n    'inp_text': LIST_FILE, 'inp_wav_dir': '', 'exp_name': EXP_NAME,\n    'opt_dir': OPT_DIR, 'is_half': 'True',\n    'i_part': '0', 'all_parts': '1', '_CUDA_VISIBLE_DEVICES': '0',\n})\n\ndef run_step(name, script, extra_env=None, timeout=900):\n    print(f\"\\n--- {name} ---\")\n    e = env.copy()\n    if extra_env: e.update(extra_env)\n    result = subprocess.run([sys.executable, '-s', script],\n        env=e, capture_output=True, text=True, timeout=timeout)\n    if result.stdout:\n        for line in result.stdout.strip().split('\\n')[-15:]:\n            print(f\"  {line}\")\n    if result.returncode != 0:\n        print(f\"  FAILED (exit {result.returncode})\")\n        if result.stderr:\n            for line in result.stderr.strip().split('\\n')[-10:]:\n                print(f\"  {line}\")\n        return False\n    return True\n\nprint(\"開始預處理...\")\nok = run_step(\"1. 文字/BERT\",\n    \"GPT_SoVITS/prepare_datasets/1-get-text.py\",\n    {'bert_pretrained_dir': f'{pretrained_base}/chinese-roberta-wwm-ext-large'})\n\nif ok:\n    ok = run_step(\"2. HuBERT\",\n        \"GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\",\n        {'cnhubert_base_dir': f'{pretrained_base}/chinese-hubert-base', 'sv_path': ''})\n\nif ok and S2G_PATH:\n    ok = run_step(\"3. Semantic\",\n        \"GPT_SoVITS/prepare_datasets/3-get-semantic.py\",\n        {'pretrained_s2G': S2G_PATH, 's2config_path': 'GPT_SoVITS/configs/s2.json'})\n\n# === 重命名: 移除 -0 後綴 (訓練腳本期望不含 part number 的檔名) ===\nprint(\"\\n後處理...\")\nfor src_pattern, dst_name in [\n    ('2-name2text-0.txt', '2-name2text.txt'),\n    ('6-name2semantic-0.tsv', '6-name2semantic.tsv'),\n]:\n    src = os.path.join(OPT_DIR, src_pattern)\n    dst = os.path.join(OPT_DIR, dst_name)\n    if os.path.exists(src) and not os.path.exists(dst):\n        os.rename(src, dst)\n        print(f\"  renamed {src_pattern} -> {dst_name}\")\n\n# === 驗證 ===\nprint(\"\\n=== 預處理結果 ===\")\nall_ok = True\nfor f in ['2-name2text.txt', '6-name2semantic.tsv']:\n    path = os.path.join(OPT_DIR, f)\n    if os.path.exists(path) and os.path.getsize(path) > 10:\n        lc = sum(1 for _ in open(path))\n        print(f\"  OK {f} ({os.path.getsize(path)} bytes, {lc} lines)\")\n    else:\n        print(f\"  FAIL {f}\")\n        all_ok = False\n\nfor d in ['3-bert', '4-cnhubert', '5-wav32k']:\n    path = os.path.join(OPT_DIR, d)\n    count = len(os.listdir(path)) if os.path.isdir(path) else 0\n    status = \"OK\" if count > 0 else \"FAIL\"\n    print(f\"  {status} {d}/ ({count} files)\")\n    if count == 0: all_ok = False\n\nif all_ok:\n    print(\"\\n\\u2705 預處理完成！所有資料就緒\")\nelse:\n    print(\"\\n\\u26a0\\ufe0f 預處理有問題，訓練可能失敗\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Step 5: 訓練 SoVITS 模型 (~10 min on T4)\nimport os, json, subprocess, sys, glob\nos.chdir(\"/content/GPT-SoVITS\")\n\nEXP_NAME = \"yuan\"\nOPT_DIR = f\"/content/GPT-SoVITS/output/training/{EXP_NAME}\"\nS2_LOG_DIR = f\"{OPT_DIR}/logs_s2_v2\"\nos.makedirs(S2_LOG_DIR, exist_ok=True)\nos.makedirs(f'SoVITS_weights/{EXP_NAME}', exist_ok=True)\n\npretrained_base = \"GPT_SoVITS/pretrained_models\"\nS2G_PATH = next((p for p in [\n    f\"{pretrained_base}/gsv-v2final-pretrained/s2G2333k.pth\",\n    f\"{pretrained_base}/s2G488k.pth\",\n] if os.path.exists(p)), '')\nS2D_PATH = next((p for p in [\n    f\"{pretrained_base}/gsv-v2final-pretrained/s2D2333k.pth\",\n    f\"{pretrained_base}/s2D488k.pth\",\n] if os.path.exists(p)), '')\n\nfor f in ['2-name2text.txt', '6-name2semantic.tsv']:\n    path = os.path.join(OPT_DIR, f)\n    if not os.path.exists(path) or os.path.getsize(path) < 10:\n        print(f\"ERROR: {f} 缺失或為空\")\n        raise SystemExit(1)\n    print(f\"OK: {f} ({os.path.getsize(path)} bytes)\")\n\nwith open('GPT_SoVITS/configs/s2.json', 'r') as f:\n    config = json.load(f)\n\n# === train 區段 ===\nconfig['train']['epochs'] = 10\nconfig['train']['batch_size'] = 16\nconfig['train']['gpu_numbers'] = '0'\nconfig['train']['save_every_epoch'] = 2\nconfig['train']['if_save_latest'] = 1\nconfig['train']['if_save_every_weights'] = True\nconfig['train']['pretrained_s2G'] = S2G_PATH\nconfig['train']['pretrained_s2D'] = S2D_PATH\nconfig['train']['half_weights_save_dir'] = f'SoVITS_weights/{EXP_NAME}'\n# === data 區段 ===\nconfig['data']['exp_dir'] = OPT_DIR\n# === model 區段 ===\nconfig['model']['version'] = 'v2'\n# === top-level (process_ckpt.py 用 hps.save_weight_dir / hps.name) ===\nconfig['s2_ckpt_dir'] = S2_LOG_DIR\nconfig['name'] = EXP_NAME\nconfig['save_weight_dir'] = f'SoVITS_weights/{EXP_NAME}'\n\nconfig_path = f'{OPT_DIR}/s2_config.json'\nwith open(config_path, 'w') as f:\n    json.dump(config, f, indent=2)\n\nprint(f\"SoVITS: epochs={config['train']['epochs']}, batch={config['train']['batch_size']}, version=v2\")\nprint(f\"開始訓練...\")\n\nresult = subprocess.run(\n    [sys.executable, '-s', 'GPT_SoVITS/s2_train.py', '--config', config_path],\n    capture_output=True, text=True, timeout=7200\n)\nif result.stdout:\n    lines = result.stdout.strip().split('\\n')\n    print(f\"\\n--- stdout (last 30 of {len(lines)}) ---\")\n    for line in lines[-30:]:\n        print(f\"  {line}\")\nif result.returncode != 0:\n    print(f\"\\nFAILED (exit {result.returncode})\")\n    if result.stderr:\n        for line in result.stderr.strip().split('\\n')[-30:]:\n            print(f\"  {line}\")\nelse:\n    print(f\"\\nExit code: {result.returncode}\")\n\nsovits_models = glob.glob(f'SoVITS_weights/{EXP_NAME}/*.pth')\nprint(f\"\\nSoVITS 模型: {len(sovits_models)}\")\nfor m in sovits_models:\n    print(f\"  {m} ({os.path.getsize(m)/1024/1024:.1f} MB)\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Step 6: 訓練 GPT 模型 (~60 min on T4)\nimport os, subprocess, sys, glob\nos.chdir(\"/content/GPT-SoVITS\")\n\nEXP_NAME = \"yuan\"\nOPT_DIR = f\"/content/GPT-SoVITS/output/training/{EXP_NAME}\"\nS1_LOG_DIR = f\"{OPT_DIR}/logs_s1\"\nos.makedirs(S1_LOG_DIR, exist_ok=True)\nos.makedirs(f'GPT_weights/{EXP_NAME}', exist_ok=True)\n\npretrained_base = \"GPT_SoVITS/pretrained_models\"\nS1_PATH = ''\nfor pat in [f\"{pretrained_base}/gsv-v2final-pretrained/s1bert25hz*.ckpt\",\n            f\"{pretrained_base}/s1bert25hz*.ckpt\"]:\n    matches = glob.glob(pat)\n    if matches:\n        S1_PATH = matches[0]\n        break\n\nSEMANTIC_PATH = f'{OPT_DIR}/6-name2semantic.tsv'\nPHONEME_PATH = f'{OPT_DIR}/2-name2text.txt'\n\nfor f in [SEMANTIC_PATH, PHONEME_PATH]:\n    if os.path.exists(f) and os.path.getsize(f) > 0:\n        print(f\"OK: {os.path.basename(f)} ({os.path.getsize(f)} bytes)\")\n    else:\n        print(f\"ERROR: {f} 缺失或為空\")\n        raise SystemExit(1)\n\nimport yaml\nyaml_candidates = ['GPT_SoVITS/configs/s1longer-v2.yaml', 'GPT_SoVITS/configs/s1longer.yaml']\nyaml_base = next((p for p in yaml_candidates if os.path.exists(p)), yaml_candidates[0])\nwith open(yaml_base, 'r') as f:\n    config = yaml.safe_load(f)\n\n# === 注入所有 runtime 必要的 config keys ===\nconfig['train']['epochs'] = 20\nconfig['train']['batch_size'] = 8\nconfig['train']['save_every_n_epoch'] = 5\n# WebUI runtime 注入的 keys (預設 yaml 不含)\nconfig['train']['if_save_latest'] = True\nconfig['train']['if_save_every_weights'] = True\nconfig['train']['half_weights_save_dir'] = f'GPT_weights/{EXP_NAME}'\nconfig['train']['exp_name'] = EXP_NAME\n# top-level\nconfig['train_semantic_path'] = SEMANTIC_PATH\nconfig['train_phoneme_path'] = PHONEME_PATH\nconfig['output_dir'] = S1_LOG_DIR\nconfig['pretrained_s1'] = S1_PATH\n\nconfig_path = f'{OPT_DIR}/s1_config.yaml'\nwith open(config_path, 'w') as f:\n    yaml.dump(config, f)\n\nprint(f\"\\nGPT config: epochs={config['train']['epochs']}, batch={config['train']['batch_size']}\")\nprint(f\"  pretrained: {S1_PATH}\")\nprint(f\"  exp_name: {EXP_NAME}\")\nprint(f\"\\n開始訓練...\")\n\nenv = os.environ.copy()\nenv['_CUDA_VISIBLE_DEVICES'] = '0'\nresult = subprocess.run(\n    [sys.executable, '-s', 'GPT_SoVITS/s1_train.py', '--config_file', config_path],\n    env=env, capture_output=True, text=True, timeout=7200\n)\n\nif result.stdout:\n    lines = result.stdout.strip().split('\\n')\n    print(f\"\\n--- stdout ({len(lines)} lines) ---\")\n    for line in lines[-30:]:\n        print(f\"  {line}\")\n\nif result.returncode != 0:\n    print(f\"\\nFAILED (exit {result.returncode})\")\n    if result.stderr:\n        for line in result.stderr.strip().split('\\n')[-30:]:\n            print(f\"  {line}\")\nelse:\n    print(f\"\\nExit code: {result.returncode}\")\n\ngpt_models = glob.glob(f'GPT_weights/{EXP_NAME}/*.ckpt')\nprint(f\"\\nGPT 模型: {len(gpt_models)}\")\nfor m in gpt_models:\n    print(f\"  {m} ({os.path.getsize(m)/1024/1024:.1f} MB)\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Step 7: 上傳模型到臨時文件服務 + 下載\nimport os, subprocess, glob\nos.chdir(\"/content/GPT-SoVITS\")\n\n# 找到最佳模型 (最高 epoch)\ngpt_models = sorted(glob.glob(\"GPT_weights/yuan/*.ckpt\"))\nsovits_models = sorted(glob.glob(\"SoVITS_weights/yuan/*.pth\"))\n\nif not gpt_models or not sovits_models:\n    print(\"ERROR: 找不到訓練模型！請確認 Step 5 和 Step 6 已成功執行。\")\n    raise SystemExit(1)\n\nbest_gpt = gpt_models[-1]\nbest_sovits = sovits_models[-1]\nprint(f\"GPT: {best_gpt} ({os.path.getsize(best_gpt)/1024/1024:.1f} MB)\")\nprint(f\"SoVITS: {best_sovits} ({os.path.getsize(best_sovits)/1024/1024:.1f} MB)\")\n\n# 上傳到 0x0.st (匿名文件分享，保留 30 天)\nurls = {}\nfor path, label in [(best_sovits, \"SOVITS\"), (best_gpt, \"GPT\")]:\n    size_mb = os.path.getsize(path) / 1024 / 1024\n    print(f\"\\n上傳 {label} ({size_mb:.0f} MB)...\")\n    r = subprocess.run(\n        [\"curl\", \"--progress-bar\", \"-F\", f\"file=@{path}\", \"https://0x0.st\"],\n        capture_output=True, text=True, timeout=600\n    )\n    if r.returncode == 0 and r.stdout.strip().startswith(\"http\"):\n        url = r.stdout.strip()\n        urls[label] = url\n        print(f\"DOWNLOAD_{label}: {url}\")\n    else:\n        print(f\"ERROR: {label} 上傳失敗\")\n        print(f\"  returncode: {r.returncode}\")\n        print(f\"  stderr: {r.stderr[:300]}\")\n\n# 儲存 URLs 到檔案\nwith open(\"/content/download_urls.txt\", \"w\") as f:\n    for label, url in urls.items():\n        f.write(f\"{label}: {url}\\n\")\n\n# 顯示下載指令\nprint(\"\\n\" + \"=\" * 60)\nprint(\"在本地 Mac 執行以下指令下載模型:\")\nprint(\"=\" * 60)\nfor label, url in urls.items():\n    fname = os.path.basename(dict([(best_sovits, \"SOVITS\"), (best_gpt, \"GPT\")]\n                                   .get(label, path) for path, l in [(best_sovits, \"SOVITS\"), (best_gpt, \"GPT\")] if l == label))\n    print(f\"  curl -L -o {os.path.basename(path)} {url}\")\nprint(\"=\" * 60)\n\n# 備用：也用 files.download 嘗試\ntry:\n    from google.colab import files\n    print(\"\\n也嘗試瀏覽器下載...\")\n    files.download(best_sovits)\n    files.download(best_gpt)\nexcept:\n    print(\"(瀏覽器下載失敗，請用上方 curl 指令)\")",
   "execution_count": null,
   "outputs": []
  }
 ]
}